{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B.K. Beaulieu-Jones, C.S. Greene, Semi-supervised learning of the electronic health record for phenotype stratification, J. Biomed. Inform. 64 (2016) 168–178. Retrieved from here code available here\n",
    "\n",
    "*    applied denoising autoencoder to simulated EHR data.\n",
    "*    also applied to ALS data obtained from Pooled Resource Open-Access ALS Clinical Trials database\n",
    "     *     ALS data contains a mix of demographic information, diagnosis history, family history, treatment history, vital sign readings, medications, laboratory values\n",
    "     *     categorical variables were converted to 1-hot encodings\n",
    "     *     repeated or temporal measurements were encoded as the mean, min, max, count, stdev, and slope accross each repeat\n",
    "     *     measurement scales were standardized and input features were normalized to be between 0 and 1 \n",
    "*    demonstrated that unsupervised learning by the DA generated distinguishable clusters analagous to population subtypes\n",
    "*    classifiers built on the DA output required significatnly fewer labeled examples to achieve optimal performance as compared to classifiers given raw input \n",
    "*    modification to handle missing data: \n",
    "     *     created a missingness vector, M, for each input with value 1 for elements where data is present, 0 otherwise\n",
    "     *     input sample, x, and reconstructed output, z, were multiplied by M\n",
    "     *     cross entropy error was divided by the sum of M\n",
    "     *     eliminates need for imputation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E. Choi, M.T. Bahadori, E. Searles, C. Coffey, J. Sun, Multi-layer Representation Learning for Medical Concepts, (2016). Retrieved from here\n",
    "\n",
    "*    objective is to develop dense vector representations of medical concept codes that encode latent information not represented in one-hot coding\n",
    "*    challenges assoicated with learning electronic health record (EHR) data representations:\n",
    "     *    EHR data structured as visits that are temporally ordered but each visit consists of an unordered set of medical codes\n",
    "     *    there is a desire to make representations interpretable\n",
    "     *    necessity to scale to large EHR data sets\n",
    "*    authors propose Med2Vec algorithm to learn code and visit level representations\n",
    "     *    demonstrated on two datasets of 3 million and 5.5 million visits\n",
    "     *    use a multi-layer perceptron architecure with ReLU\n",
    "          *     output visit layer is trained to predict visit representations for a surrounding context window\n",
    "          *     intermediate hidden layer is trained to construct code-level representations using skip-gram method\n",
    "          *     apply a non-negative weight constraint to form a non-negative matrix that allows interpretable features by finding the top k codes that have the largest values for the ith coordinate\n",
    "          *     generates code representations that are close (by consine similarity) to related concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lipton, Z. C., Kale, D. C., Elkan, C., & Wetzell, R. (2015). Learning to Diagnose with LSTM Recurrent Neural Networks. Retrieved from here\n",
    "\n",
    "*    aims to classify multivariate timeseries data into one of multiple classes using a LSTM RNN - Notes that some sequence models, such as Markov, conditional random fields, and Kalman filters are ill-equipped to learn long-range dependencies\n",
    "*    uses 13 frequently but irregularly sampled clinical measures\n",
    "*    associated w/ each patient is a subset of 429 diagnosis codes - though only focus on 128 most common\n",
    "*    classify each patient w/ 1 or more diagnosis codes\n",
    "*    test a target replication strategy for RNN in order to make a prediction at each time step \n",
    "*    population: 10,401 PICU episodes from Children’s Hospital LA. Episodes vary in length from 12 hours to several months\n",
    "*    raw data has missing values and variables (ie a given patient may have no values for a given variable)\n",
    "*    data resampled to hourly rate taking the mean measurement within the 1 hour window\n",
    "*    use forward and back filling to fill gaps. NOTE: Backfilling passes information from future to the past. This will NOT work for prediction. \n",
    "*    for missing variables - impute clinically normal values as defined by clinical experts\n",
    "*    used published tables to correct for differences in variables due to age / gender (Fleming 2011, NHBPEP Working Group 2004)\n",
    "*    RNN LSTM with memory cells with forget gates (Gers, 2000b) w/out peephole connections (Gers 2003). output layer is a fully connected layer atop last LSTM layer with element-wise sigmoid. Use log loss as the loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##2013"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasko, T. A., Denny, J. C., & Levy, M. A. (2013). Computational Phenotype Discovery Using Unsupervised Feature Learning over Noisy, Sparse, and Irregular Clinical Data. PLoS ONE, 8(6), e66341. Retrieved from here\n",
    "\n",
    "*    uses Gaussian process (GP) regression to transform raw sparse data into continuous longitudinal data for clinical measurements of uric acid levels \n",
    "     *    raw data has irregular points in time separated by interval ranging from hours to years\n",
    "     *    GP represents a probability density P(f(t)) over a space of arbitrary continuous functions. Thus it is better at capturing non-linear data patterns than the mixed-effects linear regression approach we’re using for Audiogram data\n",
    "*    used auto encoder network for unsupervised feature learning over longitudinal serum uric acid measurments\n",
    "*    demonstrated learned features useful for classifier that distinguished between gout and leukemia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
